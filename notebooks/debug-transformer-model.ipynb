{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/') \n",
    "import numpy as np\n",
    "import torch\n",
    "import Core as C\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Load Data and Batch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['accession_id', 'aligned_seqs', 'scores', 'labels', 'numerical_tokens'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unpickle file\n",
    "with open('./Pickle_storage/test_data_tokenized_WA.pkl', 'rb') as handle:\n",
    "    data, embed_map = pickle.load(handle) # We stored the data and embedding map in one file\n",
    "with open('./Pickle_storage/train_data_tokenized.pkl', 'rb') as handle:\n",
    "    data_train, embed_map_train = pickle.load(handle) # We stored the data and embedding map in one file\n",
    "\n",
    "# Visualize data\n",
    "len(pd.DataFrame(data)['labels'][8])\n",
    "pd.DataFrame(data).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accession_id</th>\n",
       "      <th>aligned_seqs</th>\n",
       "      <th>scores</th>\n",
       "      <th>labels</th>\n",
       "      <th>numerical_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EU100698</td>\n",
       "      <td>ATGAG-GACTATCA-T--TGCTTTGAGCTA-CATT-CTA-T-GTCT...</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>[0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>[0, 2, 3, 0, 3, 4, 3, 0, 1, 2, 0, 2, 1, 0, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU199367</td>\n",
       "      <td>ATGA-AGACTATCA-T--TGCTTTGAGCTA-CATT-CTA-T-GTCT...</td>\n",
       "      <td>1169.0</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, ...</td>\n",
       "      <td>[0, 2, 3, 0, 4, 0, 3, 0, 1, 2, 0, 2, 1, 0, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CY026603</td>\n",
       "      <td>TATTAACC--ATGAAGACTATCAT-TGCTTTGAGCTA-CATT-CTA...</td>\n",
       "      <td>1172.0</td>\n",
       "      <td>[1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>[2, 0, 2, 2, 0, 0, 1, 1, 4, 4, 0, 2, 3, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CY026771</td>\n",
       "      <td>TTCTATTAACC--ATGAAGACTATCAT-TGCTTTGAGCTA-CATT-...</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>[2, 2, 1, 2, 0, 2, 2, 0, 0, 1, 1, 4, 4, 0, 2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EU516081</td>\n",
       "      <td>ATGAA-AG-TA-AAACTAC-TGGTCC-T--G-T-T-AT-GC-A-CA...</td>\n",
       "      <td>1171.0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>[0, 2, 3, 0, 0, 4, 0, 3, 4, 2, 0, 4, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  accession_id                                       aligned_seqs  scores  \\\n",
       "0     EU100698  ATGAG-GACTATCA-T--TGCTTTGAGCTA-CATT-CTA-T-GTCT...  1169.0   \n",
       "1     EU199367  ATGA-AGACTATCA-T--TGCTTTGAGCTA-CATT-CTA-T-GTCT...  1169.0   \n",
       "2     CY026603  TATTAACC--ATGAAGACTATCAT-TGCTTTGAGCTA-CATT-CTA...  1172.0   \n",
       "3     CY026771  TTCTATTAACC--ATGAAGACTATCAT-TGCTTTGAGCTA-CATT-...  1171.0   \n",
       "4     EU516081  ATGAA-AG-TA-AAACTAC-TGGTCC-T--G-T-T-AT-GC-A-CA...  1171.0   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, ...   \n",
       "1  [0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, ...   \n",
       "2  [1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, ...   \n",
       "3  [1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, ...   \n",
       "4  [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, ...   \n",
       "\n",
       "                                    numerical_tokens  \n",
       "0  [0, 2, 3, 0, 3, 4, 3, 0, 1, 2, 0, 2, 1, 0, 4, ...  \n",
       "1  [0, 2, 3, 0, 4, 0, 3, 0, 1, 2, 0, 2, 1, 0, 4, ...  \n",
       "2  [2, 0, 2, 2, 0, 0, 1, 1, 4, 4, 0, 2, 3, 0, 0, ...  \n",
       "3  [2, 2, 1, 2, 0, 2, 2, 0, 0, 1, 1, 4, 4, 0, 2, ...  \n",
       "4  [0, 2, 3, 0, 0, 4, 0, 3, 4, 2, 0, 4, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.2 s, sys: 1.18 s, total: 22.3 s\n",
      "Wall time: 22.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create embedding and batch data\n",
    "ds_test = C.dataset.Dataset(data, embed=embed_map)\n",
    "#ds_test.drop_dashes()\n",
    "ds_test.make_subseqs(length=200)\n",
    "dl_test = torch.utils.data.DataLoader(ds_test, batch_size=256, pin_memory=True)  # The data loader\n",
    "\n",
    "ds_train = C.dataset.Dataset(data_train, embed=embed_map)\n",
    "#ds_train.drop_dashes()\n",
    "ds_train.make_subseqs(length=200)\n",
    "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=256, pin_memory=True)  # The data loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4163"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([math.floor(len(dl_train)*0.8), math.floor(len(dl_train)*0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1065828"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds_train.subseq_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Val Split\n",
    "train_data, val_data = torch.utils.data.random_split(\n",
    "    dl_train, [math.floor(len(dl_train)*0.9), math.floor(len(dl_train)*0.1)+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = torch.nn.TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = torch.nn.TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = torch.nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = torch.nn.Linear(ninp, 2)\n",
    "        self.softmax = torch.nn.Softmax(dim=2)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_square_subsequent_mask(sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        output = self.softmax(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Define Hyperparameters and setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(embed_map) # the size of vocabulary\n",
    "emsize = 4 # embedding dimension\n",
    "nhid = 10 # the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 3 # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 4 # the number of heads in the multiheadattention models\n",
    "dropout = 0.2 # the dropout value\n",
    "model = TransformerModel(ntokens, emsize, nhead, nhid, nlayers, dropout).to('cuda')\n",
    "writer = SummaryWriter(log_dir='./TBlogs/Test1', flush_secs=60)\n",
    "cur_batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./TBlogs/Test1’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./TBlogs/Test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sandbox: Figure out loss function\n",
    "#src_mask = model.generate_square_subsequent_mask(seq.size(0))\n",
    "#output = model(seq, src_mask).data.view(-1,2)\n",
    "#criterion(output,label.view(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Define Functions for Training and Validation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define train and validation functions\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "lr = 1e-4 # learning rate\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.8))\n",
    "#scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optimizer, lambda x: 0.99, last_epoch=100)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, threshold=0.0001, \n",
    "                                                       patience=30, cooldown=100, min_lr=1e-8)\n",
    "def train(train_data, epoch_var):\n",
    "    model.train() # Turn on the train mode\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    cur_loss_list = []\n",
    "    cur_batch = len(train_data.dataset) * epoch_var\n",
    "    for batch, data in enumerate(train_data.dataset):\n",
    "        seq, targets = data # embedded sequence, position labels\n",
    "        #print(seq.shape)\n",
    "        optimizer.zero_grad()\n",
    "        seq = seq.cuda()\n",
    "        targets = targets.cuda()\n",
    "        src_mask = model.generate_square_subsequent_mask(seq.size(0)).cuda()\n",
    "        output = model(seq, src_mask).view(-1,2)\n",
    "        loss = criterion(output, targets.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = 50\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            #elapsed = time.time() - start_time\n",
    "            #print('| epoch {:3d} | {:5d} batches | '\n",
    "            #      'ms/batch {:5.2f} | '\n",
    "            #      'loss {:5.4f} | ppl {:8.4f}'.format(\n",
    "            #        epoch, batch,\n",
    "            #        elapsed * 1000 / log_interval,\n",
    "            #        cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            #start_time = time.time()\n",
    "            cur_loss_list.append(cur_loss)\n",
    "            for pid, parameter in enumerate(model.parameters()):\n",
    "                writer.add_histogram(f'Weights/{pid}', parameter.grad, global_step=cur_batch)\n",
    "            writer.add_scalar('Loss/Train', cur_loss, cur_batch)\n",
    "            scheduler.step(cur_loss)\n",
    "        cur_batch += 1\n",
    "    return cur_loss_list\n",
    "\n",
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() # Turn on the evaluation mode\n",
    "    total_loss = 0.\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_batched in data_source.dataset:\n",
    "            seq, targets = val_batched\n",
    "            seq = seq.cuda()\n",
    "            targets = targets.cuda()\n",
    "            src_mask = model.generate_square_subsequent_mask(seq.size(0)).cuda()\n",
    "            output = eval_model(seq, src_mask).cuda().view(-1,2)\n",
    "            # Calculate loss: Might need a better way\n",
    "            total_loss += criterion(output, targets.view(-1)).item()\n",
    "    return total_loss / (len(data_source) -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 248.66757s | valid loss 5.54663 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 249.18204s | valid loss 5.52466 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 247.98830s | valid loss 5.52128 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time: 248.08887s | valid loss 5.52086 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time: 248.19201s | valid loss 5.52075 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time: 248.45433s | valid loss 5.52073 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time: 248.53782s | valid loss 5.52078 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time: 247.76938s | valid loss 5.52078 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time: 248.53060s | valid loss 5.52077 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time: 247.11153s | valid loss 5.52077 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time: 248.04880s | valid loss 5.52077 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time: 248.21587s | valid loss 5.52077 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time: 249.55825s | valid loss 5.52077 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time: 249.73246s | valid loss 5.52077 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time: 248.21458s | valid loss 5.52076 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time: 247.70159s | valid loss 5.52076 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time: 247.94272s | valid loss 5.52076 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time: 247.97357s | valid loss 5.52076 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time: 248.79565s | valid loss 5.52076 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time: 248.09744s | valid loss 5.52076 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time: 247.63720s | valid loss 5.52076 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time: 247.77420s | valid loss 5.52075 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time: 248.40714s | valid loss 5.52075 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time: 246.58603s | valid loss 5.52075 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time: 247.23785s | valid loss 5.52075 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time: 248.20614s | valid loss 5.52075 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time: 247.55114s | valid loss 5.52075 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time: 247.25080s | valid loss 5.52075 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time: 248.76718s | valid loss 5.52074 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time: 248.56803s | valid loss 5.52074 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time: 247.63047s | valid loss 5.52074 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time: 247.60392s | valid loss 5.52074 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time: 247.58685s | valid loss 5.52074 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time: 248.95514s | valid loss 5.52074 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time: 248.49844s | valid loss 5.52074 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time: 247.58771s | valid loss 5.52073 \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time: 248.38199s | valid loss 5.52073 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time: 247.89317s | valid loss 5.52073 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time: 248.44257s | valid loss 5.52073 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time: 249.08768s | valid loss 5.52073 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time: 248.43362s | valid loss 5.52073 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time: 248.80375s | valid loss 5.52073 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time: 247.27618s | valid loss 5.52073 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time: 248.43867s | valid loss 5.52072 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time: 248.38063s | valid loss 5.52072 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time: 249.34997s | valid loss 5.52072 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time: 248.18769s | valid loss 5.52072 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time: 247.98446s | valid loss 5.52072 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time: 249.76021s | valid loss 5.52072 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time: 248.57137s | valid loss 5.52072 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time: 247.78699s | valid loss 5.52071 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time: 248.09047s | valid loss 5.52071 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time: 247.66443s | valid loss 5.52071 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time: 248.86065s | valid loss 5.52071 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time: 247.57218s | valid loss 5.52071 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time: 248.56675s | valid loss 5.52071 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time: 248.71635s | valid loss 5.52071 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time: 247.92405s | valid loss 5.52070 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time: 247.85156s | valid loss 5.52070 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time: 248.13188s | valid loss 5.52070 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time: 247.74384s | valid loss 5.52070 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time: 247.88086s | valid loss 5.52070 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time: 248.92517s | valid loss 5.52070 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time: 247.59335s | valid loss 5.52070 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time: 247.43247s | valid loss 5.52070 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time: 246.76559s | valid loss 5.52069 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time: 247.59261s | valid loss 5.52069 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time: 249.50563s | valid loss 5.52069 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time: 248.86341s | valid loss 5.52069 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time: 247.90823s | valid loss 5.52069 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time: 248.26010s | valid loss 5.52069 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time: 247.95698s | valid loss 5.52069 \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time: 248.42454s | valid loss 5.52069 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time: 248.31344s | valid loss 5.52068 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time: 248.82710s | valid loss 5.52068 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time: 246.80403s | valid loss 5.52068 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time: 248.57813s | valid loss 5.52068 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time: 249.02761s | valid loss 5.52068 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time: 247.79345s | valid loss 5.52068 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time: 247.20635s | valid loss 5.52068 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time: 246.91746s | valid loss 5.52068 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time: 248.24112s | valid loss 5.52067 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time: 249.54592s | valid loss 5.52067 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time: 247.37106s | valid loss 5.52067 \n",
      "--------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time: 247.53791s | valid loss 5.52067 \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train model\n",
    "best_val_loss = float(0)\n",
    "epochs = 300 # The number of epochs\n",
    "best_model = None\n",
    "big_loss_list = []\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    big_loss_list.append(train(train_data, epoch-1))  # returns performance metrics\n",
    "    val_loss = evaluate(model, val_data)\n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.5f}s | valid loss {:5.5f} '\n",
    "          .format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss))\n",
    "    print('-' * 80)\n",
    "    writer.add_scalar('Loss/Val', val_loss, epoch)\n",
    "    if val_loss > best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = model\n",
    "    if epoch % 1 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "            }, f'./ModelSaves/Save-{epoch}-v2.pt')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fec60293fd0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(big_loss_list[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
